{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/82KJ/ARS-system-for-protecting-telephone-counselor/blob/main/SH/HomeWork/Make_Final_Dict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7QtMgW5chSj"
      },
      "source": [
        "# 1. 준비\n",
        "- cpu 환경은 너무 느려서 코랩에서 부탁드립니다 ㅎ\n",
        "- 꼭 GPU 가속이 켜져있는지 확인해주세요!\n",
        "- 추가로, 구글 드라이브에 학습 데이터, 사전 데이터, 모델을 모두 로드해 주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AXcR1zTUXbp",
        "outputId": "1bda80d2-ac48-4f11-d634-dc9300adfcb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSBlEIPocGRu",
        "outputId": "030cb376-1156-4f7f-9baf-c3528548e9c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-0xxk836j\n",
            "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-0xxk836j\n",
            "  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: boto3<=1.15.18 in /usr/local/lib/python3.9/dist-packages (from kobert==0.2.3) (1.15.18)\n",
            "Requirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: mxnet<=1.7.0.post2,>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from kobert==0.2.3) (1.7.0.post2)\n",
            "Requirement already satisfied: onnxruntime<=1.8.0,==1.8.0 in /usr/local/lib/python3.9/dist-packages (from kobert==0.2.3) (1.8.0)\n",
            "Requirement already satisfied: sentencepiece<=0.1.96,>=0.1.6 in /usr/local/lib/python3.9/dist-packages (from kobert==0.2.3) (0.1.96)\n",
            "Requirement already satisfied: torch<=1.10.1,>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from kobert==0.2.3) (1.10.1)\n",
            "Requirement already satisfied: transformers<=4.8.1,>=4.8.1 in /usr/local/lib/python3.9/dist-packages (from kobert==0.2.3) (4.8.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.22.4)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (23.3.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.3.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.19.0,>=1.18.18 in /usr/local/lib/python3.9/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (1.18.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (23.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.34)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.9/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.10.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.53)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.10.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.9/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.25.11)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB4Qc7ArjOdD",
        "outputId": "78045608-bde2-4b91-abb2-4a38b801685f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kiwipiepy in /usr/local/lib/python3.9/dist-packages (0.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from kiwipiepy) (1.22.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.9/dist-packages (from kiwipiepy) (0.6)\n",
            "Requirement already satisfied: kiwipiepy-model~=0.15 in /usr/local/lib/python3.9/dist-packages (from kiwipiepy) (0.15.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install kiwipiepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl4ydJ25do1d",
        "outputId": "8b34f2ae-6ef4-4818-be16-921e12c7d5f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cached model. /content/.cache/kobert_v1.zip\n",
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjhhqi-DeDXQ"
      },
      "source": [
        "# 2. 데이터 준비\n",
        "- 여기서는 training_dataset.csv를 활용해서 train, test set을 준비하게 됩니다!\n",
        "- 제가 디렉토리에 같이 넣어놀테니까 이거 활용하세요! --> 구글 드라이브로 옮기기\n",
        "- 추가로, 사전도 미리 준비해 놓겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiicrmHBXWnQ",
        "outputId": "ea72742c-d9d2-49ff-823f-eb96b0c67c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ARS-system-for-protecting-telephone-counselor/SH/HomeWork\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/ARS-system-for-protecting-telephone-counselor/SH/HomeWork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO8e36aAd675"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"training_dataset.csv\")\n",
        "\n",
        "data_list = list()\n",
        "for sen, lab in zip(data[\"0\"], data[\"1\"]):\n",
        "  data_list.append([sen,lab])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVIAuKD6efZO",
        "outputId": "b7b5b0d5-491d-4f6b-e3c4-58b40fe36827"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['그 동안 보빨러들이 얼마나 잘 해줬겠어ㅋㅋㅋ', 2]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(data_list, test_size=0.1, random_state=0) # train : test = 9:1\n",
        "train_set[0]\n",
        "\n",
        "# 여기서 만들어진 test_set을 중점으로 활용하시면 됩니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEly2gEjehgB",
        "outputId": "0b446c19-7d83-4f76-cf60-53f76549ac7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['인정 쟤네 목소리 쫌 심각하게 족같아', 1],\n",
              " ['나 알바하는 곳 너무 장사 잘돼서 힘들어.', 0],\n",
              " ['아슬아슬~ 정말 프로답게 벗어 주네.', 2]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set[:3]\n",
        "\n",
        "# 아래를 보면 알겠지만, 각 row마다 0번이 문장 데이터, 1번이 라벨링 데이터입니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW9glruxeoSj"
      },
      "outputs": [],
      "source": [
        "abuse = pd.read_csv(\"폭언사전.csv\")\n",
        "sexual = pd.read_csv(\"성희롱사전.csv\")\n",
        "\n",
        "# 사전은 아래에서 쓰일 거라서 미리 로드합니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "kHMAWMdJfL6e",
        "outputId": "2cb05d95-cea3-45e3-8d05-6cff98bb7655"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e95de518-2ef0-4a31-8f23-f468b8a52fcf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>가난</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>가난뱅이</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>가두</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e95de518-2ef0-4a31-8f23-f468b8a52fcf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e95de518-2ef0-4a31-8f23-f468b8a52fcf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e95de518-2ef0-4a31-8f23-f468b8a52fcf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0     0\n",
              "0           0    가난\n",
              "1           1  가난뱅이\n",
              "2           2    가두"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abuse.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "yaHt_zcEfOhh",
        "outputId": "1d3229aa-33d7-4f45-9fe6-7c4c6b84e8f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fa63b1aa-499a-4223-a8eb-2e16ddfa24c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>19금</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>69자세</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa63b1aa-499a-4223-a8eb-2e16ddfa24c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa63b1aa-499a-4223-a8eb-2e16ddfa24c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa63b1aa-499a-4223-a8eb-2e16ddfa24c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0     0\n",
              "0           0   19금\n",
              "1           1    69\n",
              "2           2  69자세"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sexual.head(3)\n",
        "\n",
        "# 사전이 dataframe으로 로드되면서, 컬럼명[Unnamed:0, 0]으로 자동 지정되었어요!\n",
        "# 여기서 '0' col을 사용하면 되겠죠?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLibdmZAfhR0"
      },
      "outputs": [],
      "source": [
        "abuse_list = list()\n",
        "sexual_list = list()\n",
        "\n",
        "for rows in abuse[\"0\"]:\n",
        "  abuse_list.append(rows)\n",
        "\n",
        "for rows in sexual[\"0\"]:\n",
        "  sexual_list.append(rows)\n",
        "\n",
        "# dataframe로 load한 사전이 사용하기 불편할 수도 있으니, 리스트 형식으로도 저장합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXMNhsVlf7E-",
        "outputId": "2395c230-8ce4-4a9c-d1a5-3b48e2c11d07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['가난', '가난뱅이', '가두'], ['19금', '69', '69자세'])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abuse_list[:3], sexual_list[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXGKWs2GgBxG"
      },
      "source": [
        "# 3. 코버트 모델 로드\n",
        "- 여기서는 저희가 만든 \"kobert_classifier.pth\"을 로드해서 모델을 준비합니다\n",
        "- 모델은 가지고 계시죠? 그거 구글 드라이브에 로드해서 사용하시면 됩니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtKReUMYf-KY",
        "outputId": "13a2878e-ae1f-429c-f6d2-42120d63c7f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cached model. /content/drive/MyDrive/ARS-system-for-protecting-telephone-counselor/SH/HomeWork/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "  def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
        "\n",
        "    # sentence , label data를 BERT의 입력값에 맞게 변환하는 transformer를 생성\n",
        "    transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_len, pad=pad, pair=pair)\n",
        "\n",
        "    ## 생성한 transformer로 sentence를 변환하여 저장\n",
        "    self.sentences = [transform([data[sent_idx]]) for data in dataset]\n",
        "    self.labels = [np.int32(data[label_idx]) for data in dataset]\n",
        "  \n",
        "  def __getitem__ (self, i):\n",
        "    return (self.sentences[i] + (self.labels[i], )) # 각 index에 맞는 item 반환 진행 --> 왜 이런 형태인지는 잘 모르겠음\n",
        "  \n",
        "  def __len__(self):\n",
        "    return (len(self.labels))\n",
        "\n",
        "# Parameter setting 진행\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5\n",
        "\n",
        "# Kobert 모듈에서 제공하는 get_tokenizer와 vocab를 활용해 tokneizer를 구성한다\n",
        "tokenizer = get_tokenizer() \n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "data_train = BERTDataset(train_set, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(test_set, 0, 1, tok, max_len, True, False)\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "  def __init__(self, bert, hidden_size = 768, num_classes=3, dr_rate=None, params=None):\n",
        "    super(BERTClassifier, self).__init__()\n",
        "    self.bert = bert\n",
        "    self.dr_rate = dr_rate\n",
        "\n",
        "    ## classifier는 선형 회귀 모델로 구성 (input size = 768, output size = 3 (label이 3개로 구성))\n",
        "    self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    ## overfitting 방지를 위한 dropout 비율 설정\n",
        "    if dr_rate:\n",
        "      self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "  # attention mask sequence를 구성해주는 함수 --> padding이 아닌 영역을 0에서 1로 변경\n",
        "  def gen_attention_mask(self, token_ids, valid_length):\n",
        "    attention_mask = torch.zeros_like(token_ids)\n",
        "    for i,v in enumerate(valid_length):\n",
        "      attention_mask[i][:v] = 1\n",
        "    \n",
        "    return attention_mask.float()\n",
        "  \n",
        "  # bert + classifier를 관통하는 forward 연산 진행\n",
        "  def forward(self, token_ids, valid_length, segment_ids):\n",
        "\n",
        "    # attention_mask 계산\n",
        "    attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "    # bert에 input 투입, 변수명이 pooler인거 보니 출력 embedding에 mean pooling 적용한 값이지 않을까 추측\n",
        "    _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "\n",
        "    # dropout 비율이 존재한다면, dropout 적용\n",
        "    if self.dr_rate:\n",
        "        out = self.dropout(pooler)\n",
        "\n",
        "    # classifier 진행\n",
        "    return self.classifier(out) \n",
        "\n",
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)\n",
        "model_state_dict = torch.load(\"kobert_classifier.pth\", map_location=device)\n",
        "model.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDFnsU6tgty1"
      },
      "source": [
        "# 4. test_set 예측 라벨 산출\n",
        "- 이제 3870개의 test 문장을 모델에 투입해서, 예측된 라벨링을 얻을 거예요!\n",
        "- 결과 라벨은 y_hat에 저장할게요~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfT_dl6Cgm2s"
      },
      "outputs": [],
      "source": [
        "def predict(predict_sentence):\n",
        "  # 1. data set 구성 (문장, 라벨)\n",
        "  data = [predict_sentence, '0']\n",
        "  dataset_another = [data]\n",
        "\n",
        "  # 2. data를 bert의 입력에 맞게 변환하기\n",
        "  another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
        "  test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=0)\n",
        "  \n",
        "  model.eval()\n",
        "\n",
        "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "      token_ids = token_ids.long().to(device)\n",
        "      segment_ids = segment_ids.long().to(device)\n",
        "      valid_length= valid_length\n",
        "      label = label.long().to(device)\n",
        "\n",
        "      # 모델 forward 연산 진행\n",
        "      out = model(token_ids, valid_length, segment_ids)\n",
        "      \n",
        "      # torch out -> numpy 형식으로 변환\n",
        "      logits = out[0].detach().cpu().numpy()\n",
        "\n",
        "      return np.argmax(logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fD4fCOmuhGjL"
      },
      "outputs": [],
      "source": [
        "y_hat = list()\n",
        "\n",
        "for rows in test_set:\n",
        "  labels = predict(rows[0])\n",
        "  y_hat.append(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKNKsW_OhPLm",
        "outputId": "a19b3a7f-a0c4-4e0b-f2f9-b18477f095f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 0, 2]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat[:3]\n",
        "\n",
        "# 이게 저희 모델로 예측한 라벨 값들 입니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6kLOD90dzvr",
        "outputId": "70ca807f-74ee-48ce-a607-651989bf73bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZZfB9Szhg7V"
      },
      "outputs": [],
      "source": [
        "y = list()\n",
        "\n",
        "for rows in test_set:\n",
        "  y.append(rows[1])\n",
        "\n",
        "# test_set은 [문장, 실제 라벨값]의 구조라서 실제 라벨값만 따로 y에 저장했어요 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-fwsxlNhkpa",
        "outputId": "1ded5605-7291-4642-a084-3eae47f5b568"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 0, 2]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[:3]\n",
        "\n",
        "# 요건 실제 라벨값 입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRfW_UXnd5oj",
        "outputId": "40e3f9b3-91ce-48e2-8367-e79f02a68339"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq-6AuNwiM7i",
        "outputId": "a078ed6b-8e4d-4f2c-bec9-d639811e11c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===Confusion Matrix===\n",
            "[[1912   54   33]\n",
            " [  62  906   43]\n",
            " [  55   42  763]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "cm = confusion_matrix(y, y_hat)\n",
        "print(\"===Confusion Matrix===\")\n",
        "print(cm)\n",
        "\n",
        "# y, y_hat으로 confusion matrix을 산출한 결과입니다\n",
        "# row는 실제 라벨\n",
        "# col은 예측 라벨\n",
        "# 즉, 0행은 실제 일반 문장 1999개에서 (1912 + 54 + 33) 1912개는 올바르게 평가, 54개는 폭언으로 잘못 산출, 33개는 성희롱으로 잘못 산출 했다는 것을 의미합니다\n",
        "# 우리의 목표는 54와 33으로 잘못 판별된 문장들을 모델 투입 전에 사전에서 미리 거를 수 있도록, 사전, 문장 각색을 진행하는 것입니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrfjAfsmgsHx"
      },
      "source": [
        "y_hat과 y 비교하여 다른 값 index_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyRnHJaEd-JQ",
        "outputId": "9e3ced84-17df-41f0-f614-f53ce9666b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[18, 21, 24, 25, 33, 34, 93, 101, 104, 117, 132, 135, 139, 142, 150, 155, 159, 162, 171, 205, 213, 225, 246, 255, 270, 285, 300, 301, 309, 327, 336, 368, 387, 388, 400, 413, 414, 417, 423, 430, 466, 470, 492, 511, 518, 527, 569, 577, 591, 621, 622, 629, 651, 658, 672, 676, 677, 678, 681, 714, 715, 716, 747, 761, 774, 788, 798, 802, 807, 817, 824, 832, 835, 875, 882, 895, 907, 942, 945, 954, 961, 963, 964, 974, 990, 1002, 1010, 1047, 1058, 1067, 1071, 1079, 1091, 1099, 1102, 1105, 1108, 1149, 1168, 1204, 1219, 1233, 1238, 1267, 1310, 1315, 1332, 1371, 1372, 1389, 1390, 1391, 1396, 1436, 1441, 1456, 1457, 1472, 1501, 1510, 1521, 1528, 1531, 1537, 1563, 1593, 1632, 1638, 1642, 1674, 1696, 1697, 1704, 1736, 1745, 1750, 1761, 1773, 1777, 1786, 1810, 1815, 1819, 1832, 1840, 1872, 1884, 1909, 1935, 1940, 1974, 1996, 2034, 2039, 2040, 2059, 2078, 2079, 2092, 2097, 2105, 2114, 2115, 2143, 2197, 2203, 2208, 2217, 2225, 2245, 2249, 2267, 2297, 2310, 2312, 2353, 2368, 2371, 2378, 2392, 2394, 2397, 2426, 2430, 2441, 2451, 2462, 2469, 2471, 2474, 2499, 2523, 2560, 2561, 2564, 2573, 2602, 2610, 2619, 2627, 2657, 2677, 2682, 2692, 2698, 2700, 2704, 2706, 2707, 2740, 2742, 2745, 2752, 2758, 2760, 2765, 2807, 2811, 2884, 2909, 2914, 2918, 2939, 2942, 2960, 2987, 2998, 3019, 3026, 3027, 3030, 3033, 3044, 3051, 3074, 3080, 3097, 3118, 3130, 3143, 3167, 3177, 3190, 3191, 3238, 3249, 3273, 3290, 3298, 3341, 3342, 3343, 3347, 3350, 3375, 3376, 3388, 3393, 3397, 3398, 3407, 3409, 3459, 3477, 3532, 3534, 3549, 3554, 3587, 3600, 3626, 3654, 3685, 3690, 3711, 3720, 3726, 3731, 3744, 3746, 3747, 3749, 3753, 3766, 3767, 3789, 3796, 3849, 3854]\n"
          ]
        }
      ],
      "source": [
        "index_list = []\n",
        "\n",
        "for i in range (len(y)):\n",
        "  if y[i] != y_hat[i]:\n",
        "    index_list.append(i)\n",
        "\n",
        "print(index_list) #289\n",
        "#print(len(index_list)) \n",
        "#근데 사실 이건 일반 아닌데 다르게 예측한 것도 포함되니깐 밑에 껄로 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PFSS5s2jZPF"
      },
      "source": [
        "# 5. 사전 각색 or 문장 각색\n",
        "- 이제 본격적인 알고리즘 작성이 필요합니다\n",
        "- 대략적인 순서는 제가 여기에 적어둘게여\n",
        "  - y 와 y_hat을 비교하면서, y==0 인데, y_hat != 0이 아닌 문장의 인덱스를 구합니다!\n",
        "  - 이제, 구한 인덱스를 바탕으로 test_set에서 문장을 찾아서, 형태소 분해 후 저장을 합니다\n",
        "  - 저장된 형태소 리스트를 바탕으로, 각각 사전의 어떤 키워드와 매칭되는지 확인합니다!\n",
        "  - 마지막으로, 사전 각색 혹은 문장 각색 두 방법 중 하나를 선택해서 진행하시면 됩니다!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0Js6NrziU4B",
        "outputId": "5dc25ca4-2bd3-4904-f3f9-93d86a6e1767"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(54, 33)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. y 와 y_hat을 비교하면서, y==0 인데, y_hat != 0이 아닌 문장의 인덱스를 구합니다! (== 실제 일반 문장인데, 폭언, 성희롱으로 잘못 예측된 문장의 인덱스)\n",
        "\n",
        "moral_abuse_idx = list() # 일반인데 폭언으로 잘못 판별된 문장의 인덱스 리스트\n",
        "moral_sexual_idx = list() # 일반인데 성희롱으로 잘못 판별된 문장의 인덱스 리스트\n",
        "\n",
        "for idx in range(len(y)):\n",
        "  if y[idx] == 0 and y_hat[idx] == 1:\n",
        "    moral_abuse_idx.append(idx)\n",
        "  elif y[idx] == 0 and y_hat[idx] == 2:\n",
        "    moral_sexual_idx.append(idx)\n",
        "\n",
        "\n",
        "# 구한 인덱스의 길이가 confusion matrix의 54, 33으로 나오겠죠?\n",
        "len(moral_abuse_idx), len(moral_sexual_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eifCjgOaoC2N",
        "outputId": "ba183dbc-c9b9-491e-b202-c4d05f6c9296"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[33,\n",
              " 104,\n",
              " 135,\n",
              " 171,\n",
              " 246,\n",
              " 368,\n",
              " 413,\n",
              " 417,\n",
              " 577,\n",
              " 672,\n",
              " 677,\n",
              " 716,\n",
              " 798,\n",
              " 961,\n",
              " 974,\n",
              " 1047,\n",
              " 1204,\n",
              " 1310,\n",
              " 1332,\n",
              " 1372,\n",
              " 1396,\n",
              " 1521,\n",
              " 1528,\n",
              " 1537,\n",
              " 1697,\n",
              " 1810,\n",
              " 2040,\n",
              " 2143,\n",
              " 2203,\n",
              " 2368,\n",
              " 2451,\n",
              " 2469,\n",
              " 2471,\n",
              " 2474,\n",
              " 2564,\n",
              " 2657,\n",
              " 2742,\n",
              " 2752,\n",
              " 2909,\n",
              " 2914,\n",
              " 3027,\n",
              " 3097,\n",
              " 3167,\n",
              " 3238,\n",
              " 3343,\n",
              " 3393,\n",
              " 3477,\n",
              " 3600,\n",
              " 3626,\n",
              " 3744,\n",
              " 3746,\n",
              " 3747,\n",
              " 3789,\n",
              " 3849]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "moral_abuse_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q99cEojgoJcN",
        "outputId": "dc3bf1bc-ccd9-4142-9221-8069fc86514b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[25,\n",
              " 142,\n",
              " 155,\n",
              " 159,\n",
              " 285,\n",
              " 301,\n",
              " 569,\n",
              " 1091,\n",
              " 1102,\n",
              " 1168,\n",
              " 1219,\n",
              " 1389,\n",
              " 1436,\n",
              " 1642,\n",
              " 1750,\n",
              " 1761,\n",
              " 2078,\n",
              " 2097,\n",
              " 2115,\n",
              " 2267,\n",
              " 2758,\n",
              " 2765,\n",
              " 2807,\n",
              " 3074,\n",
              " 3177,\n",
              " 3341,\n",
              " 3347,\n",
              " 3375,\n",
              " 3388,\n",
              " 3532,\n",
              " 3534,\n",
              " 3749,\n",
              " 3854]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "moral_sexual_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUHO8HX2kwEE",
        "outputId": "1fae6f68-5731-45c5-b8d2-54ba05729e04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[33, ['야', '짱개', '언어', '그냥', '모르', '어도', '되', '거든', '?']]\n",
            "[25, ['성관계', '끝나', '었', '는데', '도', '계속', '이쁘', '다고', '하', '어', '주', '고', '이름', '이랑', '전화', '번호', '도', '알리', '어', '주', '네', '.']]\n"
          ]
        }
      ],
      "source": [
        "# 2. 찾은 인덱스를 바탕으로 test_set에서 문장을 찾고, 형태소 분해 후 저장해요\n",
        "from kiwipiepy import Kiwi\n",
        "kiwi = Kiwi()\n",
        "\n",
        "moral_abuse_morphs = list()    # 일반인데 폭언으로 잘못 판별된 문장의 형태소 리스트\n",
        "moral_sexual_morphs = list()   # 일반인데 성희롱으로 잘못 판별된 문장의 형태소 리스트\n",
        "\n",
        "#(1) 폭언\n",
        "for idx in moral_abuse_idx: #폭언으로 잘못판별된 문장의 리스트 인덱스로\n",
        "  morphs = kiwi.tokenize(test_set[idx][0]) #테스트 셋 문장을 찾고 형태소 분해\n",
        "  temp = list()\n",
        "  for morph in morphs:\n",
        "    temp.append(morph.form)\n",
        "  moral_abuse_morphs.append([idx,temp])\n",
        "\n",
        "#(2) 성희롱\n",
        "for idx in moral_sexual_idx:\n",
        "  morphs = kiwi.tokenize(test_set[idx][0])\n",
        "  temp = list()\n",
        "  for morph in morphs:\n",
        "    temp.append(morph.form)\n",
        "  moral_sexual_morphs.append([idx,temp])\n",
        "\n",
        "print(moral_abuse_morphs[0]) #이거는 잘못 판별된 애들\n",
        "print(moral_sexual_morphs[0])\n",
        "\n",
        "# 출력된 결과를 보면, 짱개, 성관계 등의 형태소가 포함되어 있어서 두 문장에 대한 표현은 사실 일반 문장이라고 보기 힘듭니다.. ㅜ\n",
        "# 아래 문장들은 사실, 일반 문장 데이터 만들 때 제거되었어야 맞는데.. 흠.. 누군가 대충 넘어가서 이런 결과가.. ㅎ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynliQ3wHmXfS",
        "outputId": "616dc1bd-a136-4d07-829a-e0f3cd6bfa1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[33, ['야', '짱개', '언어', '그냥', '모르', '어도', '되', '거든', '?'], ['짱개', '어도'], ['어도']]\n",
            "\n",
            "[104, ['걔', '네', '이름', '부터', '정', '떨어지', 'ᆷ', 'ㅋㅋ', '평생', '땅', '치', '고', '후회', '하', '었', '으면'], ['정', '떨어지', '땅', '치'], ['정', '으면']]\n",
            "\n",
            "[135, ['안락사', '는', '죽음', '을', '존엄', '하', '게', '맞', '을', '수', '있', '게', '돕', '자는', '거', '이', 'ᆫ데', '.'], ['안락사', '죽음', '맞', '자는'], ['자는']]\n",
            "\n",
            "[171, ['저번', '대선', '홍', '이', '문', '개털', '었', '는데', '?', '탄핵', '때문', '에', '지', 'ᆫ', '거', '이', '야'], ['홍'], ['는데']]\n",
            "\n",
            "[246, ['너', '아이스크림', '먹', '고', '싶', '다며', '나', '가', '배', '민', '으로', '시키', '어', '주', 'ᆯ까', '?'], ['먹', '시키'], ['먹', '배', '시키', '주']]\n",
            "\n",
            "[368, ['나', '그냥', '멍', '때리', '고', '있', '었', '어'], ['멍', '때리'], ['때리']]\n",
            "\n",
            "[413, ['감방', '가', '어서', '도', '또', '사기치', '어', '먹', '을', '궁리', '하', '겠', '지', '점점', '더', '지능', '것', '으로', '크', 'ᆫ', '사기치력', '이', '고', '열심히', '연구', '하', '겠', '구만', '하', '는', '넘', '은', '또', '하', '지', '.'], ['감방', '사기치', '먹', '지능', '크', '넘'], ['어서', '먹', '크']]\n",
            "\n",
            "[417, ['아니야', '장애', '있', '는', '사람', '들', '도', '결혼', '잘', '하', '어서', '아이', '도', '잘', '낳', '을', '수', '있', '게', '하', '어', '주', '어야지'], ['장애', '사람', '들', '잘', '잘', '낳', '어야지'], ['장애', '들', '잘', '어서', '잘', '낳', '주']]\n",
            "\n",
            "[577, ['형국', '을', '알', '어야', '너', '같', '은', '놈', '한테', '도', '짓밟히', '지', '않', '을', '거', '알', '냐'], ['놈'], ['알', '어야', '한테', '알', '냐']]\n",
            "\n",
            "[672, ['저', '놈', '아버지', '가', '일본', '놈', '밑', '에서', '마름질', '하', '었었', '어', '.'], ['놈', '놈', '밑'], ['밑']]\n",
            "\n",
            "[677, ['아', '진짜', '?', '슬슬', '단물', '빠지', 'ᆫ', '듯', '때리', '어', '치', '어라'], ['빠지', '때리', '치', '어라'], ['진짜', '빠지', '때리', '어라']]\n",
            "\n",
            "[716, ['판사', '가족', '이', '당하', '었', '으면', '사형', '감', '이', '지', '.'], ['가족', '당하', '사형', '감'], ['당하', '으면', '감']]\n",
            "\n",
            "[798, ['지지자', '들', '은', '지', 'ᆯ', '때', '도', '조용히', '지', '게', '내버리', '어', '두', '지', 'ᆯ', '않', '네', '.'], ['들', '내버리', '두'], ['들', '때']]\n",
            "\n",
            "[961, ['삼시샛기', '차리', '어', '주', '니까', '고맙', '은', '줄', '도', '모르', '고', '.', '이제', '부터', '너', '가', '하', '어', '보', 'ᆯ래', '?'], ['차리', '줄'], ['주', '니까', '줄', '보']]\n",
            "\n",
            "[974, ['그냥', '좀', '닥치', '고', '게임', '이나', '하', '지', '?'], ['닥치', '이나'], ['좀', '이나']]\n",
            "\n",
            "[1047, ['나', 'ᆫ', '시체', '토막', '을', '보', '면', '잔뜩', '흥분', '되', '더라'], ['시체', '토막'], ['보', '흥분', '더라']]\n",
            "\n",
            "[1204, ['남자', '들', '은', '다', '도살', '시키', '어', '버리', '었', '음', '좋', '겠', '어', '세계', '평화', '는', '남자', '사살', '이', '지', '뭐'], ['들', '도살', '시키', '버리', '좋', '사살'], ['남자', '들', '시키', '버리', '좋', '남자']]\n",
            "\n",
            "[1310, ['1', '단계', '는', '솔직히', '부모', '입김', '아니', '었', '으면', '발끝', '도', '못', '따라가', '었', '다'], ['부모'], ['으면']]\n",
            "\n",
            "[1332, ['나', '는', '일찍', '죽', '을', '만', '하', 'ᆫ', '멍청하', 'ᆫ', '짓', '은', '하', '지', '않', '을래'], ['죽', '멍청하', '짓'], ['죽', '짓']]\n",
            "\n",
            "[1372, ['아', '진짜', '개빡', '치', 'ᆫ다'], ['개빡', '치'], ['진짜']]\n",
            "\n",
            "[1396, ['님', '존예보스', '이', 'ᆫ', '거', '같', '어요', '.'], [], []]\n",
            "\n",
            "[1521, ['걔', '는', '그', '사람', '잘생기', '었', '다고', '지지', '하', '는', '빠돌', '이', '더라'], ['사람', '지지'], ['잘생기', '더라']]\n",
            "\n",
            "[1528, ['뭐', '타투', '하', 'ᆯ', '수', '는', '있', '는데', '저렇', '게', '팔', '덮', '은', '자식', '이랑', '은', '겸상', '도', '하', '지', '말', '어'], ['팔', '자식', '말'], ['는데', '팔', '말']]\n",
            "\n",
            "[1537, ['저런', '미개', '하', 'ᆫ', '것', '들', '을', '우리', '가', '왜', '따라하', 'ᆫ다고', '헛', '소리', '하', '는', '거', '이', '야', '?'], ['미개', '들', '헛', '소리'], ['미개', '들', '우리']]\n",
            "\n",
            "[1697, ['나', '어제', '하체', '헬스', '로', '조지', '었', '더니', '못', '걷', '겠', '어'], ['조지', '걷'], ['하체']]\n",
            "\n",
            "[1810, ['저러', '다', '떨어지', '면', '어쩌', '려고', '그렇', '어', '?', '뒤지', '려면', '지', '혼자', '뒤지', '지'], ['떨어지', '뒤지', '뒤지'], ['저러', '혼자']]\n",
            "\n",
            "[2040, ['이혼', '소송', '지', '어서', '돈', '이나', '줄창', '뜯기', '었', '으면', '좋', '겠', '다', '.'], ['이나', '뜯기', '좋'], ['어서', '돈', '이나', '으면', '좋']]\n",
            "\n",
            "[2143, ['그니까', '걍', '쓰레기', '같', '은', '애', '들', '이', '다'], ['쓰레기', '들'], ['들']]\n",
            "\n",
            "[2203, ['참교육', '가', '어야', '겠', '네'], ['참교육'], ['어야']]\n",
            "\n",
            "[2368, ['아니', '근데', '지', '얘기', '도', '재밌', '으면', '모르', '어', '재미', '도', '디지게', '없', '어', '가지', '고', 'ㅋㅋ'], ['디지게', '가지'], ['으면', '가지']]\n",
            "\n",
            "[2451, ['아', '배', '아프', '어', '요새', '변비', '이', 'ᆫ지', '똥', '이', '안', '나오', '어', 'ㅠㅠ', '미치', '겠', '어'], ['똥', '나오', '미치'], ['배', '변비', '똥']]\n",
            "\n",
            "[2469, ['가만히', '있', '어', '이', '벌레', '이', '야', '.'], ['벌레'], []]\n",
            "\n",
            "[2471, ['방역', '못', '하', '면', '돌멩이', '던지', 'ᆯ', '거', '이', '다'], ['돌멩이', '던지'], ['던지']]\n",
            "\n",
            "[2474, ['진짜', '철딱서니', '가', '없', '어도', '너무', '없', '어'], ['어도'], ['진짜', '어도']]\n",
            "\n",
            "[2564, ['부모', '세대', '에', '는', '자식', '없', '으면', '그냥', '장애인', '취급', '당하', '던', '사회', '이', '었', '는데', '가난', '하', 'ᆫ', '부모', '들', '이', '좋', '어서', '애', '를', '낳', '었', '겠', '냐'], ['부모', '자식', '장애인', '취급', '당하', '사회', '가난', '부모', '들', '좋', '낳'], ['으면', '당하', '는데', '들', '좋', '어서', '낳', '냐']]\n",
            "\n",
            "[2657, ['진짜', '쓰', 'ᆯ', '때', '마다', '개', '빡', '치', '네'], ['쓰', '개', '빡', '치'], ['진짜', '쓰', '때', '마다', '빡']]\n",
            "\n",
            "[2742, ['도련님', '못', '하', '겠', '으면', '아이', '삼촌', '이', '라고', '하', '어라'], ['어라'], ['으면', '어라']]\n",
            "\n",
            "[2752, ['그냥', '개취', '같', '더라고'], [], []]\n",
            "\n",
            "[2909, ['야', '걔', '네', '도', '나름', '개과천선', '하', '어서', '열심히', '하', 'ᆫ', '거', '이', '야'], [], ['어서']]\n",
            "\n",
            "[2914, ['너', '진짜', '핑프', '같', '어'], [], ['진짜']]\n",
            "\n",
            "[3027, ['나', '는', '학교', '가', 'ᆯ', '준비', '도', '하', '어야', '하', '고', '보통', '은', '엄마', '가', '차리', '어', '주', '지', '않', '어', '너', '는', '니', '가', '차리', '어', '먹', '냐', '??'], ['엄마', '차리', '차리', '먹'], ['어야', '엄마', '주', '먹', '냐']]\n",
            "\n",
            "[3097, ['여보', '식', '세기', '한', '대', '사', '자', '설거지', '하', '기', '힘들', '어', 'ㅜㅜ'], ['식', '대'], ['대', '사', '자', '설거지']]\n",
            "\n",
            "[3167, ['덜미', '만', '잡히', 'ᆫ', '것', '이', '아니', '라', '모가지', '까지', '잡히', 'ᆫ', '거', '이', 'ᆸ니다', '.'], ['모가지'], ['까지']]\n",
            "\n",
            "[3238, ['너', '지금', '부리', '또', '사', '어', '오', 'ᆫ', '거', '이', '고', '기', '말', '고', '뭐', '가', '들', '어', '있', '는', '거', '이', '야', '?'], ['부리', '말', '들'], ['사', '말', '들']]\n",
            "\n",
            "[3343, ['아무리', '국선', '변호사', '이', '라도', '양심', '이', '있', '으면', '죄', '를', '인정', '하', 'ᆫ다고', '하', '어야지', ',', '저런', '애', '들', '이', '사회', '에', '나오', '어서', '개', '차', '반', '으로', '살', 'ᆯ', '거', '뻔히', '알', '면서', '.'], ['라도', '양심', '죄', '인정', '어야지', '들', '사회', '나오', '개', '반', '살', '면서'], ['으면', '들', '어서', '살', '알']]\n",
            "\n",
            "[3393, ['맞', '어', '.', '나', '는', '살인', '이랑', '동급', '이', '라고', '보', '어'], ['맞', '살인'], ['보']]\n",
            "\n",
            "[3477, ['사형', '은', '시키', '면', '안', '되', '어'], ['사형', '시키'], ['시키']]\n",
            "\n",
            "[3600, ['1000', '원', '에', '반찬', '세', '개', '랑', '밥', ',', '국', '나오', '면', '혜자', '아니', 'ᆷ', '?'], ['개', '밥', '국', '나오'], ['세', '밥']]\n",
            "\n",
            "[3626, ['나', '도', '흑인', '으로', '살', 'ᆯ', '바', '에', 'ᆫ', '그냥', '다음', '생', '도박', '하', 'ᆯ', '듯'], ['흑인', '살', '도박'], ['흑인', '살']]\n",
            "\n",
            "[3744, ['남', '의', '나라', '에서', '돈', '받', '어', '가', '는', '주제', '에', '감', '내놔라', '배', '내', '어', '놓', '어라', '하', '네', '.'], ['주제', '감', '놓', '어라'], ['돈', '받', '감', '배', '놓', '어라']]\n",
            "\n",
            "[3746, ['장사', '하', '는', '사람', '들', '은', '물건', '안', '팔리', '면', '가게', '다', '불', '지르', '어야', '하', '나', '?'], ['사람', '들', '불', '지르'], ['장사', '들', '물건', '불', '지르', '어야']]\n",
            "\n",
            "[3747, ['성형', '괴물', '길거리', '에', '좀', '안', '나오', '었', '으면', '좋', '겠', '다'], ['괴물', '길거리', '나오', '좋'], ['좀', '으면', '좋']]\n",
            "\n",
            "[3789, ['저', '예쁘', 'ᆫ', '아가', '를', '어떻', '게', '굶기', '어', '죽이', '냐'], ['예쁘', '아가', '굶기', '죽이'], ['예쁘', '어떻', '죽이', '냐']]\n",
            "\n",
            "[3849, ['나', '는', '말', '하', '는', '감자', '이', '야', '.'], ['말', '감자'], ['말']]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3. 우선, 폭언으로 잘못 판별된 문장들이 사전의 어느 부분이랑 매칭되는지 확인해볼까요?\n",
        "# 이때, 사전은 폭언, 성희롱 사전 모두 사용하셔야 됩니다 --> 실제 시스템에서 두개다 매칭을 진행할거라서 ㅇㅇ\n",
        "\n",
        "\n",
        "#잘못 판별된 애들이 사전에 어디랑 매칭되어 있는지 확인 \n",
        "for rows in moral_abuse_morphs:\n",
        "  abuse_matched = list()\n",
        "  sexual_matched = list()\n",
        "\n",
        "  for morph in rows[1]:\n",
        "    if morph in abuse_list:\n",
        "      abuse_matched.append(morph)\n",
        "    if morph in sexual_list:\n",
        "      sexual_matched.append(morph)\n",
        "\n",
        "  rows.append(abuse_matched)\n",
        "  rows.append(sexual_matched)\n",
        "\n",
        "for rows in moral_abuse_morphs:\n",
        "  print(rows)\n",
        "  print()\n",
        "\n",
        "# 폭언으로 잘못 분류된 문장 모두에 대해 (test_set 인덱스, 문장 형태소, 폭언 사전 매칭 형태소, 성희롱 사전 매칭 형태소)\n",
        "# 보면 1396이랑,2752 인덱스는 어떤 사전이랑도 매칭되는 게 없잖아요. 바로 해당 문장들이 사전을 적용하게 되면, 매칭이 되는게 없어서 바로 일반 문장으로 판단되는 문장들입니다!\n",
        "# 제가 말했었죠. 그 사전 적용하면 딱 2문장만 걸러진다고요. 그게 바로 이 두문장입니다!!\n",
        "# 그러니까, 지금 저희가 하는 일이. 이 두문장 말고도 사전에 매칭되는 문장이 없게끔 문장, 사전을 각색하는 일입니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5QRxqCQKG_M"
      },
      "source": [
        "여기서부터 사전 각색"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dHmjgxdopUM"
      },
      "outputs": [],
      "source": [
        "# 4. 사전 각색 방법\n",
        "\n",
        "# 위에 문장 중에서, 171 인덱스 문장을 바탕으로 사전을 각색하는게 좋아보여요\n",
        "# 폭언 사전에서는 '홍', 성희롱 사전에서는 '는데'만 매칭되었거든요\n",
        "# 그럼 해당 키워드를 제거하기 전에, 기존에 '홍', '는데' 키워드만 가지고 있던 폭언, 성희롱 문장이 있을 수도 있어요\n",
        "# 그런 문장이 있는지 확인해봐여\n",
        "\n",
        "def isOnlyThatKeyword(keyword):\n",
        "  res = list()\n",
        "\n",
        "  for rows in test_set:\n",
        "    if rows[1] == 1 or rows[1] == 2:  \n",
        "      temp_all = list()\n",
        "      temp_abuse = list()\n",
        "      temp_sexual = list()\n",
        "      morphs = kiwi.tokenize(rows[0])\n",
        "\n",
        "      flag = False\n",
        "      for morph in morphs:\n",
        "        if morph.form == keyword:\n",
        "          flag =True\n",
        "      \n",
        "      if flag == True:\n",
        "        for morph in morphs:\n",
        "          temp_all.append(morph.form)\n",
        "\n",
        "          if morph.form in abuse_list:\n",
        "            temp_abuse.append(morph.form)\n",
        "          if morph.form in sexual_list:\n",
        "            temp_sexual.append(morph.form)\n",
        "        \n",
        "      if len(temp_abuse) + len(temp_sexual) == 1:\n",
        "        res.append([temp_all, temp_abuse, temp_sexual])\n",
        "      \n",
        "\n",
        "  return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWPguDAru045",
        "outputId": "7aa45fad-0a3d-4506-c597-c62cdceb40f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "isOnlyThatKeyword('홍')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDSuoOgowPW_",
        "outputId": "5a04df5f-0b30-4f0e-d4ef-082fde1e5053"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "isOnlyThatKeyword('는데') # 홍, 는데만으로 매칭되는 폭언, 성희롱 문장은 업네여!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfPnr3zJQNIh"
      },
      "source": [
        "한번에 isOnlyThatKeyword하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc9mLKUuTbpX"
      },
      "outputs": [],
      "source": [
        "temp_abuse_list = [] #매칭된 것 중에 폭언 매칭 한번에 담은 리스트\n",
        "temp_sexual_list = [] #매칭된 것 중에 성희롱 매칭 한번에 담은 리스트\n",
        "for rows in moral_abuse_morphs:\n",
        "  for item in rows[2]:\n",
        "    temp_abuse_list.append(item)\n",
        "  \n",
        "  for item in rows[3]:\n",
        "    temp_sexual_list.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIkEpzIWpHMU",
        "outputId": "ab588c3d-9de6-40a7-fad7-89950bfa963f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n"
          ]
        }
      ],
      "source": [
        "idx_list = []\n",
        "for rows in moral_abuse_morphs:\n",
        "  for item in str(rows[0]):\n",
        "    idx_list.append(item)\n",
        "\n",
        "print(len(idx_list))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEneRFSfq2uN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91pqSkIMV2cO",
        "outputId": "ca998259-46be-48c0-9827-2a586ca39545"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['어도',\n",
              " '정',\n",
              " '으면',\n",
              " '자는',\n",
              " '는데',\n",
              " '먹',\n",
              " '배',\n",
              " '시키',\n",
              " '주',\n",
              " '때리',\n",
              " '어서',\n",
              " '먹',\n",
              " '크',\n",
              " '장애',\n",
              " '들',\n",
              " '잘',\n",
              " '어서',\n",
              " '잘',\n",
              " '낳',\n",
              " '주',\n",
              " '알',\n",
              " '어야',\n",
              " '한테',\n",
              " '알',\n",
              " '냐',\n",
              " '밑',\n",
              " '진짜',\n",
              " '빠지',\n",
              " '때리',\n",
              " '어라',\n",
              " '당하',\n",
              " '으면',\n",
              " '감',\n",
              " '들',\n",
              " '때',\n",
              " '주',\n",
              " '니까',\n",
              " '줄',\n",
              " '보',\n",
              " '좀',\n",
              " '이나',\n",
              " '보',\n",
              " '흥분',\n",
              " '더라',\n",
              " '남자',\n",
              " '들',\n",
              " '시키',\n",
              " '버리',\n",
              " '좋',\n",
              " '남자',\n",
              " '으면',\n",
              " '죽',\n",
              " '짓',\n",
              " '진짜',\n",
              " '잘생기',\n",
              " '더라',\n",
              " '는데',\n",
              " '팔',\n",
              " '말',\n",
              " '미개',\n",
              " '들',\n",
              " '우리',\n",
              " '하체',\n",
              " '저러',\n",
              " '혼자',\n",
              " '어서',\n",
              " '돈',\n",
              " '이나',\n",
              " '으면',\n",
              " '좋',\n",
              " '들',\n",
              " '어야',\n",
              " '으면',\n",
              " '가지',\n",
              " '배',\n",
              " '변비',\n",
              " '똥',\n",
              " '던지',\n",
              " '진짜',\n",
              " '어도',\n",
              " '으면',\n",
              " '당하',\n",
              " '는데',\n",
              " '들',\n",
              " '좋',\n",
              " '어서',\n",
              " '낳',\n",
              " '냐',\n",
              " '진짜',\n",
              " '쓰',\n",
              " '때',\n",
              " '마다',\n",
              " '빡',\n",
              " '으면',\n",
              " '어라',\n",
              " '어서',\n",
              " '진짜',\n",
              " '어야',\n",
              " '엄마',\n",
              " '주',\n",
              " '먹',\n",
              " '냐',\n",
              " '대',\n",
              " '사',\n",
              " '자',\n",
              " '설거지',\n",
              " '까지',\n",
              " '사',\n",
              " '말',\n",
              " '들',\n",
              " '으면',\n",
              " '들',\n",
              " '어서',\n",
              " '살',\n",
              " '알',\n",
              " '보',\n",
              " '시키',\n",
              " '세',\n",
              " '밥',\n",
              " '흑인',\n",
              " '살',\n",
              " '돈',\n",
              " '받',\n",
              " '감',\n",
              " '배',\n",
              " '놓',\n",
              " '어라',\n",
              " '장사',\n",
              " '들',\n",
              " '물건',\n",
              " '불',\n",
              " '지르',\n",
              " '어야',\n",
              " '좀',\n",
              " '으면',\n",
              " '좋',\n",
              " '예쁘',\n",
              " '어떻',\n",
              " '죽이',\n",
              " '냐',\n",
              " '말']"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_sexual_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjG-NLs8mBz2",
        "outputId": "209d1047-eec6-4c56-ba73-e6db3fd8704f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "for item in temp_abuse_list :\n",
        "  tem = \"'\"+item+\"'\"\n",
        "  print(isOnlyThatKeyword(tem))\n",
        "\n",
        "#왜 안나올까?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfiBc_ksyA48",
        "outputId": "7132c635-fc72-442e-c8b6-78e8d1a8e4f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['저번대선 홍이 문 개털었는데? 탄핵때문에 진거야', 0]\n"
          ]
        }
      ],
      "source": [
        "# 홍, 는데 모두 각 키워드만으로 매칭되는 실제 폭언, 성희롱 문장이 없다네요\n",
        "# 즉, 사전에서 해당 두 키워드를 즉시 삭제해도, 무관하다는 뜻입니다\n",
        "# 이렇게 경우의 수를 전부 계산해서 사전 csv 에서 키워드를 삭제하면 됩니다\n",
        "# 단, 유의할 점은 이렇게 사전에서 키워드를 삭제하면, 다른 문장 검증시 갱신된 사전을 바탕으로 진행해야 합니다 --> 그냥 하면 미세한 확률로 에러가 날 수도! ㅎ\n",
        "\n",
        "# 그래서 두번째 방법을 알려드립니다\n",
        "\n",
        "print(test_set[171])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JKsXtKOyu0R"
      },
      "outputs": [],
      "source": [
        "# 5. 문장 각색\n",
        "\n",
        "# 예를 들어, 위의 171번 문장에서 문제가 되는게, [홍, 는데] 두개니까\n",
        "example = \"저번대선 김이 문 이김, 탄핵때문에 진거야\"\n",
        "# 이런식으로 홍,는데 를 없애서 회피하듯이 문장을 다시 짜는 겁니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2Zq5nKQzI7e"
      },
      "outputs": [],
      "source": [
        "# 해당 문장은 문제가 없는지 검증해볼까요\n",
        "\n",
        "def validation(sentence):\n",
        "  morphs = kiwi.tokenize(example)\n",
        "  flag = False\n",
        "  for morph in morphs:\n",
        "    if morph.form in abuse_list or morph.form in sexual_list:\n",
        "      print(morph.form)\n",
        "      flag = True\n",
        "  \n",
        "  if flag == False:\n",
        "    print(\"문장 각색 완료\")\n",
        "  else:\n",
        "    print(\"위의 키워드가 문제가 됩니다. 문장을 다시 각색하세요!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXQJ_DbrzjoQ",
        "outputId": "7f878cee-e93c-42b7-c0bc-8cf013fda19a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "김\n",
            "이기\n",
            "위의 키워드가 문제가 됩니다. 문장을 다시 각색하세요!\n"
          ]
        }
      ],
      "source": [
        "validation(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t01Q7PBC0U57",
        "outputId": "7f0cb5ef-c2a4-4b4e-ad75-868e4214e487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장 각색 완료\n"
          ]
        }
      ],
      "source": [
        "# 각색 결과 또 문제가 생기네여 ㅋㅋㅋㅋㅋㅋㅋㅋ\n",
        "# 그럼 이번에는 이렇게 바꿀게여\n",
        "example = \"저번대선 윤이 문 개텀, 탄핵때문에 진거야\"\n",
        "validation(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juh7WsO9qclN"
      },
      "source": [
        "문장검색"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zne9eMNEn7OP",
        "outputId": "57ee968e-b595-48e4-9fd2-eed61d872503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['걔네 이름부터 정 떨어짐 ㅋㅋ 평생 땅 치고 후회했으면', 0]\n"
          ]
        }
      ],
      "source": [
        "print(test_set[104])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz-Zb8xQsa1N",
        "outputId": "5a6a56ed-f8ee-45db-8755-196499cf79e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장 각색 완료\n"
          ]
        }
      ],
      "source": [
        "example = \"걔네 이름부터 감명 없음 ㅋㅋ 평생 수영 하고 후회하면\"\n",
        "validation(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJI0tFsDtK7i",
        "outputId": "c6f95d6f-0235-42ee-acd6-0383cfbad1e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['안락사는 죽음을 존엄하게 맞을 수 있게 돕자는 건데.', 0]\n"
          ]
        }
      ],
      "source": [
        "print(test_set[135])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD2xPjP3tQtW",
        "outputId": "319660c5-ccde-4278-8664-19cf1c6b8b43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장 각색 완료\n"
          ]
        }
      ],
      "source": [
        "example = \"분만은 탄생을 존엄하게 할 수 있게 돕는 건데\"\n",
        "validation(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHpZ6Bp8vUl0",
        "outputId": "805335e0-daef-49ca-b26f-011bba43b24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['너 아이스크림 먹고 싶다며 내가 배민으로 시켜줄까?', 0]\n"
          ]
        }
      ],
      "source": [
        "print(test_set[246])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3jvIh8xvZjo",
        "outputId": "16c3d2d6-44b2-4712-d23a-dfb35bf47850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장 각색 완료\n"
          ]
        }
      ],
      "source": [
        "example = \"너 아이스크림 갖고 싶다며 내가 요기요로 주문할까?\"\n",
        "validation(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TChgqP4Zwakr",
        "outputId": "21e1544e-df80-4179-eba3-085b17f031df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['나 그냥 멍 때리고 있었어', 0]\n"
          ]
        }
      ],
      "source": [
        "print(test_set[368])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEXK6ky7wfQH"
      },
      "outputs": [],
      "source": [
        "example = \"나 그냥 발 펴고 있었어\"\n",
        "validation(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlf1KhWiVyvc",
        "outputId": "6019d05a-6983-4d6a-e361-ae5b258fef92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['짱개',\n",
              " '어도',\n",
              " '정',\n",
              " '떨어지',\n",
              " '땅',\n",
              " '치',\n",
              " '안락사',\n",
              " '죽음',\n",
              " '맞',\n",
              " '자는',\n",
              " '홍',\n",
              " '먹',\n",
              " '시키',\n",
              " '멍',\n",
              " '때리',\n",
              " '감방',\n",
              " '사기치',\n",
              " '먹',\n",
              " '지능',\n",
              " '크',\n",
              " '넘',\n",
              " '장애',\n",
              " '사람',\n",
              " '들',\n",
              " '잘',\n",
              " '잘',\n",
              " '낳',\n",
              " '어야지',\n",
              " '놈',\n",
              " '놈',\n",
              " '놈',\n",
              " '밑',\n",
              " '빠지',\n",
              " '때리',\n",
              " '치',\n",
              " '어라',\n",
              " '가족',\n",
              " '당하',\n",
              " '사형',\n",
              " '감',\n",
              " '들',\n",
              " '내버리',\n",
              " '두',\n",
              " '차리',\n",
              " '줄',\n",
              " '닥치',\n",
              " '이나',\n",
              " '시체',\n",
              " '토막',\n",
              " '들',\n",
              " '도살',\n",
              " '시키',\n",
              " '버리',\n",
              " '좋',\n",
              " '사살',\n",
              " '부모',\n",
              " '죽',\n",
              " '멍청하',\n",
              " '짓',\n",
              " '개빡',\n",
              " '치',\n",
              " '사람',\n",
              " '지지',\n",
              " '팔',\n",
              " '자식',\n",
              " '말',\n",
              " '미개',\n",
              " '들',\n",
              " '헛',\n",
              " '소리',\n",
              " '조지',\n",
              " '걷',\n",
              " '떨어지',\n",
              " '뒤지',\n",
              " '뒤지',\n",
              " '이나',\n",
              " '뜯기',\n",
              " '좋',\n",
              " '쓰레기',\n",
              " '들',\n",
              " '참교육',\n",
              " '디지게',\n",
              " '가지',\n",
              " '똥',\n",
              " '나오',\n",
              " '미치',\n",
              " '벌레',\n",
              " '돌멩이',\n",
              " '던지',\n",
              " '어도',\n",
              " '부모',\n",
              " '자식',\n",
              " '장애인',\n",
              " '취급',\n",
              " '당하',\n",
              " '사회',\n",
              " '가난',\n",
              " '부모',\n",
              " '들',\n",
              " '좋',\n",
              " '낳',\n",
              " '쓰',\n",
              " '개',\n",
              " '빡',\n",
              " '치',\n",
              " '어라',\n",
              " '엄마',\n",
              " '차리',\n",
              " '차리',\n",
              " '먹',\n",
              " '식',\n",
              " '대',\n",
              " '모가지',\n",
              " '부리',\n",
              " '말',\n",
              " '들',\n",
              " '라도',\n",
              " '양심',\n",
              " '죄',\n",
              " '인정',\n",
              " '어야지',\n",
              " '들',\n",
              " '사회',\n",
              " '나오',\n",
              " '개',\n",
              " '반',\n",
              " '살',\n",
              " '면서',\n",
              " '맞',\n",
              " '살인',\n",
              " '사형',\n",
              " '시키',\n",
              " '개',\n",
              " '밥',\n",
              " '국',\n",
              " '나오',\n",
              " '흑인',\n",
              " '살',\n",
              " '도박',\n",
              " '주제',\n",
              " '감',\n",
              " '놓',\n",
              " '어라',\n",
              " '사람',\n",
              " '들',\n",
              " '불',\n",
              " '지르',\n",
              " '괴물',\n",
              " '길거리',\n",
              " '나오',\n",
              " '좋',\n",
              " '예쁘',\n",
              " '아가',\n",
              " '굶기',\n",
              " '죽이',\n",
              " '말',\n",
              " '감자']"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_abuse_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4sTOKN80inA"
      },
      "outputs": [],
      "source": [
        "# 이번에는 문제가 없네여!\n",
        "# 그럼 해당 문장을 csv에서 바꿔주면 됩니다!\n",
        "\n",
        "# ㅎㅎ.. 복잡하죠 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\n",
        "# 사전 각색 vs 문장 각색 비교하면, 아무래도 문장 각색이 신경쓸게 덜합니다  \n",
        "# 사전 각색이 귀찮은 이유는 사전에서 키워드를 제거하고 갱신된 사전을 다시 코랩으로 로드하고 다음 문장을 작업해야하기 때문입니다 (갱신 안하고 작업하면, 정확한 산출이 불가)\n",
        "\n",
        "# 그래서 왠만하면 적절하게 문장을 각색하고 검증하는 방식을 이용하면 됩니다!\n",
        "# 하지만, 제가 사용한 예시 문장처럼 '는데' 이런 말도안되는 키워드가 문제가 되면, 아무래도 사전 자체에서 삭제하는 편이 좋겠죠?\n",
        "# --> 판단은 알아서!, 사전 각색이 귀찮으면, 전부 문장 각색으로 하셔도 됩니다~ --> 제가 봤을 때는 '는데'만 삭제하고 이후에는 그냥 문장 각색으로 빠르게 해도 될 것 같네요\n",
        "\n",
        "# 위의 알고리즘에서 3번부터는 폭언으로 잘 못 판별한 문장으로만 진행 중입니다\n",
        "# 그러니까 성희롱으로 잘 못 판별한 문장에서도 각색이 필요해요!\n",
        "# 성희롱 코드는 아래에서 확인!\n",
        "\n",
        "# 이렇게 30문장 정도만 추가로 거르면 좋을 것 같아요! 고생하세여! ㅎ  (죄송해요ㅜ 많으면 많을 수록 좋을 것 같아요..ㅎ)\n",
        "# 아 각색 과정에서, 사전을 수정했으면, 어떤 키워드를 수정했는지\n",
        "# 문장을 수정했으면 어떤 문장을 수정했는지 인덱스 정보를 기록해두세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuK7vOi62o5R",
        "outputId": "443acfd3-04e7-45a7-925b-88dbfd5328c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[25, ['성관계', '끝나', '었', '는데', '도', '계속', '이쁘', '다고', '하', '어', '주', '고', '이름', '이랑', '전화', '번호', '도', '알리', '어', '주', '네', '.'], ['알리'], ['성관계', '는데', '주', '주']]\n",
            "\n",
            "[142, ['애견', '카페', '가', '었', '는데', '나', '의', '옆', '에서', '강아지', '들', '짝짓기', '하', 'ᆷ', '..'], ['들'], ['는데', '옆', '들', '짝짓기']]\n",
            "\n",
            "[155, ['새', '거', '도', '아니', 'ᆫ', '스타킹', '으로', '포장', '되', '어', '있', '음'], ['새'], ['스타킹']]\n",
            "\n",
            "[159, ['러시아', '여자', '들', '이', '리얼', '예쁘', 'ᆷ'], ['여자', '들', '예쁘'], ['여자', '들', '예쁘']]\n",
            "\n",
            "[285, ['잘', '찍', '고', '오', '었', '지', '~', '근데', '가슴', '이', '작', '어서', '곤란', '하', '었', '음'], ['잘', '찍', '가슴', '작'], ['잘', '찍', '가슴', '작', '어서']]\n",
            "\n",
            "[301, ['무슨', '대단', '하', 'ᆫ', '집', '아들', '이', 'ᆫ', '줄', '알', '었', '더니', '남자', '개털', '이', '구만'], ['아들', '줄'], ['무슨', '줄', '알', '남자']]\n",
            "\n",
            "[569, ['넘', '귀엽', '지', '않', '냐', '??', '저', '정도', '이', '면', '강아지', '탈', '을', '쓰', 'ᆫ', '사람', '아니', 'ᆯ까', 'ㅋㅋ'], ['넘', '탈', '쓰', '사람'], ['냐', '탈', '쓰']]\n",
            "\n",
            "[1091, ['ㄹㅇ', '거기', '에', '돈', '쓰', '는', '아재', '가', '얼마나', '많', '은데'], ['거기', '쓰', '아재', '많'], ['거기', '돈', '쓰', '많']]\n",
            "\n",
            "[1102, ['평소', '에', '덜렁대', '었', '잖아', '.', '너', '도', '알', '면서'], ['면서'], ['알']]\n",
            "\n",
            "[1168, ['2', '년', '동안', '구르', '고', '박', '고', '얻', '어', '터지', 'ᆫ', '적', '없', '으면', '입', '딱', '다물', '어라'], ['년', '구르', '박', '터지', '적', '입', '딱', '다물', '어라'], ['년', '구르', '박', '터지', '적', '으면', '입', '딱', '어라']]\n",
            "\n",
            "[1219, ['달고나', '가', '뭐', '가', '맛있', '다고', '난리', '들', '이', '야', ';'], ['난리', '들'], ['맛있', '들']]\n",
            "\n",
            "[1389, ['쟤', '가', '아직', '도', '뮤지컬', '쪽', '에서', '는', '몸값', '탑', '이', '야', '.'], [], ['몸값', '탑']]\n",
            "\n",
            "[1436, ['청국장', '좋아하', '는', '애', '들', '보', '면', '아재', '입맛', '이', 'ᆫ', '거', '같', '은데', '좀', '그렇', '다'], ['들', '아재'], ['들', '보', '좀']]\n",
            "\n",
            "[1642, ['우리', '겜방', '가', '어서', '겜', '한판', '만', '하', '자'], [], ['우리', '어서', '한판', '자']]\n",
            "\n",
            "[1750, ['환자', '덮치', '는', '의사', '가', '의사', '이', '냐'], ['환자'], ['덮치', '냐']]\n",
            "\n",
            "[1761, ['막', '줍', '다가', '잡히', '어', '가', '는', '거', '아니', '야', '?', 'ㅋㅋ'], ['막'], ['막', '다가']]\n",
            "\n",
            "[2078, ['머', '가', '있', '어야', '적을거잔아요', '나', 'ᆫ', '장점', '없', '어요', '.'], ['머'], ['머', '어야']]\n",
            "\n",
            "[2097, ['가슴', '크', 'ᆫ', '여자', '들', '크로스', '백', '메', '는', '거'], ['가슴', '크', '여자', '들', '메'], ['가슴', '크', '여자', '들']]\n",
            "\n",
            "[2115, ['이거', '보', '면', '배꼽', '빠지', 'ᆷ'], ['빠지'], ['보', '배꼽', '빠지']]\n",
            "\n",
            "[2267, ['분명히', '해', '쨍쨍', '하', 'ᆯ', '거', '이', '라', '하', '었었', '는데'], [], ['해', '는데']]\n",
            "\n",
            "[2758, ['우리', '어리', 'ᆯ', '때', '는', '피카츄', '진짜', '많이', '먹', '었', '는데', 'ㅎ'], ['어리', '먹'], ['우리', '어리', '때', '진짜', '먹', '는데']]\n",
            "\n",
            "[2765, ['니', '딸', '도', '아니', 'ᆫ데', '40', '대', '를', '만나', '어', '들', 'ᆫ', '50', '대', '를', '만나', '든', '왜', '열', '폭', '이', '냐'], ['딸', '대', '들', '대', '폭'], ['딸', '대', '만나', '들', '대', '만나', '폭', '냐']]\n",
            "\n",
            "[2807, ['우리', '나라', '는', '아직', '야매', '가', '많이', '서', '글', '치', '멋지', 'ᆫ데', '?'], ['서', '치'], ['우리', '서', '글']]\n",
            "\n",
            "[3074, ['저쪽', '은', '엉덩이', '수술', '많이', '하', 'ᆫ대', '요'], [], ['엉덩이', '수술']]\n",
            "\n",
            "[3177, ['왜', '화', '를', '내', '어', '~', '몰카', '야', 'ㅋㅋ'], ['화', '몰카'], ['화', '몰카']]\n",
            "\n",
            "[3341, ['아', '뭐', '이', '라는', '거', '이', '야', '얘', '네', '츄르', '에', '환장', '하', '어'], ['환장'], []]\n",
            "\n",
            "[3347, ['여자', '친구', '를', '사귀', '면', '헤프', '게', '놀', '는', '거', '이', '야', '?'], ['여자', '사귀'], ['여자', '친구', '헤프', '놀']]\n",
            "\n",
            "[3375, ['남', '의', '집', '복도', '계단', '에서', '어떤', '놈', '이', '딸', '치', '다가', 'cctv', '에', '찍히', '었', '대'], ['놈', '딸', '치', '찍히', '대'], ['딸', '다가', '대']]\n",
            "\n",
            "[3388, ['누구', '가', '자꾸', '나', '의', '속옷', '훔치', '어', '가', 'ᆫ다', '누구', '이', '냐'], [], ['속옷', '냐']]\n",
            "\n",
            "[3532, ['그냥', '다', '밈', '이', '지', '설마', '진짜', '이', '겠', '냐'], [], ['진짜', '냐']]\n",
            "\n",
            "[3534, ['나', 'ᆫ', '단벌', '숙녀', '이', '야', '그러', 'ᆯ', '수', '있', '자', 'ᆫ', '아'], [], ['자']]\n",
            "\n",
            "[3749, ['사자', '의', '저', '멋지', 'ᆫ', '갈기', '들', '이', '더', '멋지', '게', '보이', '는', '거', '같', '애'], ['사자', '갈기', '들', '보이'], ['갈기', '들', '보이']]\n",
            "\n",
            "[3854, ['오키나와', '여행', '가', '었', '을', '때', '까마귀', '가', '가방', '지퍼', '열', '고', '빵', '꺼내', '어', '가', '더라', 'ㅋㅋ'], ['빵', '꺼내'], ['때', '빵', '더라']]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 부록. 성희롱으로 잘 못 판별한 문장\n",
        "\n",
        "for rows in moral_sexual_morphs:\n",
        "  abuse_matched = list()\n",
        "  sexual_matched = list()\n",
        "\n",
        "  for morph in rows[1]:\n",
        "    if morph in abuse_list:\n",
        "      abuse_matched.append(morph)\n",
        "    if morph in sexual_list:\n",
        "      sexual_matched.append(morph)\n",
        "\n",
        "  rows.append(abuse_matched)\n",
        "  rows.append(sexual_matched)\n",
        "\n",
        "for rows in moral_sexual_morphs:\n",
        "  print(rows)\n",
        "  print()\n",
        "\n",
        "# 성희롱으로 잘못 분류된 문장 모두에 대해 (test_set 인덱스, 문장 형태소, 폭언 사전 매칭 형태소, 성희롱 사전 매칭 형태소)\n",
        "# 제가 봤을 때는 1102, 2078, 2267 요런 문장들이 각색하기 편해 보이네여"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}